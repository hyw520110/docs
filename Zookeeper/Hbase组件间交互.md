<p><strong>Hbase实现</strong><br>&nbsp;&nbsp;&nbsp; Hbase由一个Master节点负责协调管理一个或多个RegionServer从属机.Master负责启动,把区域分配给注册的RegionServer,恢复RegionServer的故障. Master负载很轻. RegionServer负责零个或多个区域的管理以及响应客户端的读写请求, RegionServer还负责区域的划分,并通知Master有了新的子区域Hbase依赖于Zookeeper.如果区域的分配过程中有服务器崩溃,就通过Zookeeper来协调,分配,在Zookeeper分配事务状态有助于在恢复时可以从崩溃遗留的状态开始继续分配.在启动一个客户端到集群上的连接时,客户端必须至少拿到集群所传递的Zookeeper整体的位置.这样,客户端才能访问Zookeeper的层次,了解集群的属性,如服务器的位置.<br><strong>运行中Hbase</strong><br>&nbsp;&nbsp;&nbsp; Hbase中保留着-ROOT-和.META.的特殊目录,它们维护着当前集群上所有区域的列表,状态,位置.ROOT表维护着Meta表的信息,Meta表维护着用户表的信息, Meta表中的项使用区域名作为主键,区域名由所属的表名,区域的起始行,创建的时间戳进行哈希后的结果组成.区域变化时,即分裂,禁用/启用.删除,为负载均衡重新部署机器或由于Regionserver崩溃而重新部署区域时,目录表都会相应进行更新,这样,集群上所以区域的信息都能保持是最新的.<br>客户端的每一个行操作都要访问三次远程节点:<br>&nbsp;&nbsp;&nbsp;&nbsp;1.从Zookeeper获取Master的位置<br>&nbsp;&nbsp;&nbsp;&nbsp;2.从Master获取.Meta.表的信息<br>&nbsp;&nbsp;&nbsp;&nbsp;3.根据.Meta.表的信息,获取region位置信息<br></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;为了减少访问远程节点,Hbase客户端会缓存它们遍历ROOT表时获取的信息和Meta表位置以及用户空间的区域的开始行和结束行,这样不用访问Meta表也能得知区域存放的位置.当客户端碰到错误时会再去查看Meta获取区域的新位置,如果.Meta也移动了,就去查询ROOT表&nbsp;</p>
<hr>
<p><strong>Client</strong></p>
<p>1 包含访问hbase的接口，client维护着一些cache来加快对hbase的访问，比如regione的位置信息。<br><strong>Zookeeper</strong><br>1 保证任何时候，集群中只有一个master<br>2 存贮所有Region的寻址入口。<br>3 实时监控Region Server的状态，将Region server的上线和下线信息实时通知给Master<br>4 存储Hbase的schema,包括有哪些table，每个table有哪些column family<br><strong>Master</strong><br>1 为Region server分配region<br>2 负责region server的负载均衡<br>3 发现失效的region server并重新分配其上的region<br>4 GFS上的垃圾文件回收<br>5 处理schema更新请求<br><strong>Region Server</strong><br>1 Region server维护Master分配给它的region，处理对这些region的IO请求<br>2 Region server负责切分在运行过程中变得过大的region<br>可以看到，client访问hbase上数据的过程并不需要master参与（寻址访问zookeeper和region server，数据读写访问regione server），master仅仅维护者table和region的元数据信息，负载很低</p>
<hr>
<p><strong>region定位</strong><br>系统如何找到某个row key (或者某个 row key range)所在的region<br>bigtable 使用三层类似B+树的结构来保存region位置。<br>第一层是保存zookeeper里面的文件，它持有root region的位置。<br>第二层root region是.META.表的第一个region其中保存了.META.z表其它region的位置。通过root region，我们就可以访问.META.表的数据。<br>.META.是第三层，它是一个特殊的表，保存了hbase中所有数据表的region 位置信息。<br>说明：<br>1 root region永远不会被split，保证了最需要三次跳转，就能定位到任意region 。<br>2.META.表每行保存一个region的位置信息，row key 采用表名+表的最后一样编码而成。<br>3 为了加快访问，.META.表的全部region都保存在内存中。<br>假设，.META.表的一行在内存中大约占用1KB。并且每个region限制为128MB。<br>那么上面的三层结构可以保存的region数目为：<br>(128MB/1KB) * (128MB/1KB) = = 2(34)个region<br>4 client会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的region(其中三次用来发现缓存失效，另外三次用来获取位置信息)。<br><strong>读写过程</strong><br>上文提到，hbase使用MemStore和StoreFile存储对表的更新。<br>数据在更新时首先写入Log(WAL log)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并 且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时，系统会在zookeeper中 记录一个redo point，表示这个时刻之前的变更已经持久化了。(minor compact)<br>当系统出现意外时，可能导致内存(MemStore)中的数据丢失，此时使用Log(WAL log)来恢复checkpoint之后的数据。<br>前面提到过StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更 新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact),将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行split，等分为两个StoreFile。<br>由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的 StoreFile和MemStore，将他们的按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，合并的过程还是比较快。<br><strong>写请求处理过程</strong><br>1 client向region server提交写请求<br>2 region server找到目标region<br>3 region检查数据是否与schema一致<br>4 如果客户端没有指定版本，则获取当前系统时间作为数据版本<br>5 将更新写入WAL log<br>6 将更新写入Memstore<br>7 判断Memstore的是否需要flush为Store文件。<br><strong>region分配</strong><br>任何时刻，一个region只能分配给一个region server。master记录了当前有哪些可用的region server。以及当前哪些region分配给了哪些region server，哪些region还没有分配。当存在未分配的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。<br></p>
<p><br></p>
<hr>
<p><strong>region server上线</strong></p>
<p>master使用zookeeper来跟踪region server状态。当某个region server启动时，会首先在zookeeper上的server目录下建立代表自己的文件，并获得该文件的独占锁。由于master订阅了server 目录上的变更消息，当server目录下的文件出现新增或删除操作时，master可以得到来自zookeeper的实时通知。因此一旦region server上线，master能马上得到消息。<br><strong>region server下线</strong><br>当region server下线时，它和zookeeper的会话断开，zookeeper而自动释放代表这台server的文件上的独占锁。而master不断轮询 server目录下文件的锁状态。如果master发现某个region server丢失了它自己的独占锁，(或者master连续几次和region server通信都无法成功),master就是尝试去获取代表这个region server的读写锁，一旦获取成功，就可以确定：<br>1 region server和zookeeper之间的网络断开了。<br>2 region server挂了。<br>的其中一种情况发生了，无论哪种情况，region server都无法继续为它的region提供服务了，此时master会删除server目录下代表这台region server的文件，并将这台region server的region分配给其它还活着的同志。<br>如果网络短暂出现问题导致region server丢失了它的锁，那么region server重新连接到zookeeper之后，只要代表它的文件还在，它就会不断尝试获取这个文件上的锁，一旦获取到了，就可以继续提供服务。<br><strong>master上线</strong><br>master启动进行以下步骤:<br>1 从zookeeper上获取唯一一个代码master的锁，用来阻止其它master成为master。<br>2 扫描zookeeper上的server目录，获得当前可用的region server列表。<br>3 和2中的每个region server通信，获得当前已分配的region和region server的对应关系。<br>4 扫描.META.region的集合，计算得到当前还未分配的region，将他们放入待分配region列表。<br><strong>master下线</strong><br>由于master只维护表和region的元数据，而不参与表数据IO的过 程，master下线仅导致所有元数据的修改被冻结(无法创建删除表，无法修改表的schema，无法进行region的负载均衡，无法处理region 上下线，无法进行region的合并，唯一例外的是region的split可以正常进行，因为只有region server参与)，表的数据读写还可以正常进行。因此master下线短时间内对整个hbase集群没有影响。从上线过程可以看到，master保存的 信息全是可以冗余信息（都可以从系统其它地方收集到或者计算出来），因此，一般hbase集群中总是有一个master在提供服务，还有一个以上 的’master’在等待时机抢占它的位置。<br><br></p>
