<p><span style="font-family:'微软雅黑', 'Microsoft YaHei';">&nbsp;Hadoop系列之zookeeper(分布式协调服务)安装配置 <br>1.安装<br>cd /root/soft<br>tar zxvf zookeeper-3.4.6.tar.gz<br>mv zookeeper-3.4.6 /usr/local/hadoop/zookeeper<br>2.修改配置文件<br>mkdir -p /data/zookeeper/data //3个节点都需要创建此目录<br>cd /usr/local/hadoop/zookeeper/conf<br>cp zoo_sample.cfg zoo.cfg<br>#vim zoo.cfg(修改并添加配置文件)</span></p>
<pre class="brush:xml;toolbar:false">tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/zookeeper/data
clientPort=2181
server.1=hdfs-master:2888:3888&nbsp;
server.2=hdfs-slave1:2888:3888&nbsp;
server.3=hdfs-slave2:2888:3888</pre>
<p><span style="font-family:'微软雅黑', 'Microsoft YaHei';"></span><span style="font-family:'微软雅黑', 'Microsoft YaHei';">#添加/data/zookeeper/data/myid配置文件<br>&nbsp;echo 1 &gt; /data/zookeeper/data/myid <br>&nbsp;//在其它两个节点myid的值分别是2,3<br>#添加环境变量 /etc/profile&nbsp; //3个节点都需要添加环境变量<br>ZOOKEEPER=/usr/local/hadoop/zookeeper<br>PATH=$PATH:$ZOOKEEPER/bin<br>#执行环境变量生效<br>&nbsp;source /etc/profile<br>3.将文件分发到集群其它DataNode节点上<br>&nbsp;scp -r /usr/local/hadoop/zookeeper root@192.168.3.11:/usr/local/hadoop/<br>&nbsp;scp -r /usr/local/hadoop/zookeeper root@192.168.3.12:/usr/local/hadoop/<br>4.启动服务<br>#所有节点执行启动命令<br>zkServer.sh start<br>#在其中一台机器上执行客户端脚本，来查看这台服务器是否启动：<br>zkCli.sh -server 192.168.3.10:2181<br>5.查看状态<br>5.1 执行jps查看状态<br>#在NameNode查看<br>[root@hdfs-master conf]# jps<br>17928 Jps<br>17862 QuorumPeerMain<br>2282 SecondaryNameNode<br>2127 NameNode<br>2437 ResourceManager<br>#在DataNode查看<br>[root@hdfs-slave1 hadoop]# jps<br>7211 Jps<br>7148 QuorumPeerMain<br>836 DataNode<br>5.2 查看zookeeper集群是否启动<br>#在NameNode查看<br>[root@hdfs-master conf]# zkServer.sh status<br>JMX enabled by default<br>Using config: /usr/local/hadoop/zookeeper/bin/../conf/zoo.cfg<br>Mode: follower<br>#在DataNode查看<br>&nbsp;[root@hdfs-slave1 hadoop]# zkServer.sh status<br>JMX enabled by default<br>Using config: /usr/local/hadoop/zookeeper/bin/../conf/zoo.cfg<br>Mode: leader<br>6.ZooKeeper的命令行操作<br>#ls,查看/目录内容<br>[zk: 192.168.3.10:2181(CONNECTED) 1] ls /<br>[zookeeper]<br>#create,创建一个znode节点<br>[zk: 192.168.3.10:2181(CONNECTED) 4] create /node conan<br>Created /node<br>#ls,再查看/目录<br>[zk: 192.168.3.10:2181(CONNECTED) 5] ls /<br>[node, zookeeper]<br>#get,查看/node的数据信息<br>[zk: 192.168.3.10:2181(CONNECTED) 6]&nbsp; get /node<br>conan<br>cZxid = 0x100000004<br>ctime = Thu Sep 18 11:43:10 CST 2014<br>mZxid = 0x100000004<br>mtime = Thu Sep 18 11:43:10 CST 2014<br>pZxid = 0x100000004<br>cversion = 0<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0x0<br>dataLength = 5<br>numChildren = 0<br><br>备注:<br>如果hadoop上面启动了hbase并且用了自带的zookeeper,则独立安装的zookeeper无法启动，<br>此时测试独立安装的zookeeper，需要先把hbase服务关闭测试，如果想继续使用hbase功能，<br>建议把hbase配置修改成独立的zookeeper,不用系统自带的zookeeper服务。</span><br></p>
<p>本文出自 “<a href="http://azhuang.blog.51cto.com">成都@阿状</a>” 博客，请务必保留此出处<a href="http://azhuang.blog.51cto.com/9176790/1554669">http://azhuang.blog.51cto.com/9176790/1554669</a></p>
